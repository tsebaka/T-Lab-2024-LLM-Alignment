{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install trl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-05T14:15:29.635498Z","iopub.execute_input":"2024-08-05T14:15:29.636321Z","iopub.status.idle":"2024-08-05T14:15:44.072307Z","shell.execute_reply.started":"2024-08-05T14:15:29.636284Z","shell.execute_reply":"2024-08-05T14:15:44.071323Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting trl\n  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.1.2)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from trl) (4.42.3)\nRequirement already satisfied: numpy<2.0.0,>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl) (1.26.4)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl) (0.32.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl) (2.20.0)\nCollecting tyro>=0.5.11 (from trl)\n  Downloading tyro-0.8.5-py3-none-any.whl.metadata (8.2 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2024.5.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.23.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (4.66.4)\nCollecting docstring-parser>=0.16 (from tyro>=0.5.11->trl)\n  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.0)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl) (5.9.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.9.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->trl) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (2024.7.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\nDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.8.5-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\nDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, docstring-parser, tyro, trl\n  Attempting uninstall: docstring-parser\n    Found existing installation: docstring-parser 0.15\n    Uninstalling docstring-parser-0.15:\n      Successfully uninstalled docstring-parser-0.15\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed docstring-parser-0.16 shtab-1.7.1 trl-0.9.6 tyro-0.8.5\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport transformers\nimport datasets\n\nfrom tqdm import tqdm\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\nfrom trl import RewardTrainer, RewardConfig","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:15:44.074759Z","iopub.execute_input":"2024-08-05T14:15:44.075537Z","iopub.status.idle":"2024-08-05T14:16:02.757017Z","shell.execute_reply.started":"2024-08-05T14:15:44.075496Z","shell.execute_reply":"2024-08-05T14:16:02.756055Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-05 14:15:53.081593: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-05 14:15:53.081694: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-05 14:15:53.198492: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"PATH = \"distilbert/distilbert-base-cased\"\n\nreward_model = AutoModelForSequenceClassification.from_pretrained(\n    PATH, \n    num_labels=1\n)\ntokenizer = AutoTokenizer.from_pretrained(PATH)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:16:02.758210Z","iopub.execute_input":"2024-08-05T14:16:02.758872Z","iopub.status.idle":"2024-08-05T14:16:05.661159Z","shell.execute_reply.started":"2024-08-05T14:16:02.758844Z","shell.execute_reply":"2024-08-05T14:16:05.660226Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1e6ad8a2fc14d60a7d1f8d8b1346721"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/263M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db71afbf19ea45b8b487dac990f146b4"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc10f1939c9c4fe182610c06b56b852b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da5b5e5200104203838722da213803d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63c2dd94441b4c038239ad83d942d343"}},"metadata":{}}]},{"cell_type":"code","source":"dataset = load_dataset(\"stanfordnlp/imdb\")\n\ntrain_dataset = dataset[\"train\"]\n\npositive_comments = [tokenizer.encode_plus(comment[\"text\"], \n                                           truncation=True, padding=\"max_length\",\n                                           max_length=128) for comment in train_dataset if comment[\"label\"] == 1][0:1000]\nnegative_comments = [tokenizer.encode_plus(comment[\"text\"],\n                                           truncation=True, padding=\"max_length\",\n                                           max_length=128) for comment in train_dataset if comment[\"label\"] == 0][0:1000]\n\npairs = [(pos, neg) for pos in positive_comments for neg in negative_comments]","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:16:05.663213Z","iopub.execute_input":"2024-08-05T14:16:05.663531Z","iopub.status.idle":"2024-08-05T14:16:47.428654Z","shell.execute_reply.started":"2024-08-05T14:16:05.663503Z","shell.execute_reply":"2024-08-05T14:16:47.427814Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/7.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8f0fa63f0af4f609bdda80b7783bf8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/21.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8553736844dc402c90fa7df71232f59c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/20.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ef0f78248ea46c9aa9e6769340d9863"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/42.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14def26b56f14386acc89060fa43b2b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e909524e00644d49979e9f61edf2dda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b57bd83052f407da51b864d7fc0a53e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ff10c91079e4ae89019ff2bb7f4983a"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(pairs):\n    pair = {\n        \"input_ids_chosen\": [],\n        \"attention_mask_chosen\": [],\n        \"input_ids_rejected\": [],\n        \"attention_mask_rejected\": [],\n    }\n    for chosen, rejected in tqdm(pairs):\n\n        pair[\"input_ids_chosen\"].append(chosen[\"input_ids\"])\n        pair[\"attention_mask_chosen\"].append(chosen[\"attention_mask\"])\n        pair[\"input_ids_rejected\"].append(rejected[\"input_ids\"])\n        pair[\"attention_mask_rejected\"].append(rejected[\"attention_mask\"])\n\n    return pair\n\nprocessed_pairs = preprocess_function(pairs)\n\nprocessed_dataset = Dataset.from_dict(processed_pairs)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:16:47.429833Z","iopub.execute_input":"2024-08-05T14:16:47.430155Z","iopub.status.idle":"2024-08-05T14:18:46.115569Z","shell.execute_reply.started":"2024-08-05T14:16:47.430128Z","shell.execute_reply":"2024-08-05T14:18:46.114670Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"100%|██████████| 1000000/1000000 [00:02<00:00, 384324.05it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = RewardConfig(\n    output_dir=\".\",  \n    save_strategy=\"no\",     \n    num_train_epochs=1,     \n    report_to=\"none\",      \n    learning_rate=1e-6,\n    per_device_train_batch_size=64,\n)\n\ntrainer = RewardTrainer(\n    model=reward_model,\n    args=training_args,\n    tokenizer=tokenizer,\n    train_dataset=processed_dataset,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:18:46.118583Z","iopub.execute_input":"2024-08-05T14:18:46.118930Z","iopub.status.idle":"2024-08-05T14:18:46.692693Z","shell.execute_reply.started":"2024-08-05T14:18:46.118896Z","shell.execute_reply":"2024-08-05T14:18:46.691696Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/reward_trainer.py:175: UserWarning: When using RewardDataCollatorWithPadding, you should set `max_length` in RewardConfig. It will be set to `512` by default, but you should do it yourself in the future.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/reward_trainer.py:192: UserWarning: When using RewardDataCollatorWithPadding, you should set `remove_unused_columns=False` in your RewardConfig we have set it for you, but you should do it yourself in the future.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Проверил, можно на 2000 степах просто остановить и уже будет окей","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:18:46.693893Z","iopub.execute_input":"2024-08-05T14:18:46.694178Z","iopub.status.idle":"2024-08-05T14:18:54.402250Z","shell.execute_reply.started":"2024-08-05T14:18:46.694152Z","shell.execute_reply":"2024-08-05T14:18:54.400967Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2778: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\nCould not estimate the number of tokens of the input, floating-point operations will not be computed\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [    6/15625 00:02 < 3:08:05, 1.38 it/s, Epoch 0.00/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2273\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2268\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2271\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2273\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2274\u001b[0m ):\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2276\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"reward_model.save_pretrained(\"reward_model\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:18:58.549226Z","iopub.execute_input":"2024-08-05T14:18:58.549636Z","iopub.status.idle":"2024-08-05T14:18:59.078946Z","shell.execute_reply.started":"2024-08-05T14:18:58.549599Z","shell.execute_reply":"2024-08-05T14:18:59.077914Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Проверочка","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"stanfordnlp/imdb\")\n\ntrain_dataset = dataset[\"test\"]\n\npositive_comments = [tokenizer.encode_plus(comment[\"text\"], truncation=True, padding=\"max_length\", max_length=128) for comment in train_dataset if comment[\"label\"] == 1][0:100]\nnegative_comments = [tokenizer.encode_plus(comment[\"text\"], truncation=True, padding=\"max_length\", max_length=128) for comment in train_dataset if comment[\"label\"] == 0][0:100]\n\npairs = [(pos, neg) for pos in positive_comments for neg in negative_comments]\n\nfrom datasets import load_dataset, Dataset, DatasetDict","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:01:11.215279Z","iopub.execute_input":"2024-08-05T12:01:11.216027Z","iopub.status.idle":"2024-08-05T12:01:42.458438Z","shell.execute_reply.started":"2024-08-05T12:01:11.215995Z","shell.execute_reply":"2024-08-05T12:01:42.457447Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"reward_model.to(\"cuda\")\n\n\ndef preprocess_function(pairs):\n    pair = {\n        \"input_ids_chosen\": [],\n        \"attention_mask_chosen\": [],\n        \"input_ids_rejected\": [],\n        \"attention_mask_rejected\": [],\n    }\n    for chosen, rejected in tqdm(pairs):\n\n        pair[\"input_ids_chosen\"].append(chosen[\"input_ids\"])\n        pair[\"attention_mask_chosen\"].append(chosen[\"attention_mask\"])\n        pair[\"input_ids_rejected\"].append(chosen[\"input_ids\"])\n        pair[\"attention_mask_rejected\"].append(chosen[\"attention_mask\"])\n\n    return pair\n\nprocessed_pairs = preprocess_function(pairs)\n\nprocessed_dataset = Dataset.from_dict(processed_pairs)\n\ntargets = []\nlabels = []\nfor i in tqdm(range(len(train_dataset))):\n    tokens = tokenizer.encode_plus(train_dataset[i][\"text\"], truncation=True, padding=\"max_length\", max_length=128) \n\n    output = reward_model.forward(input_ids=torch.tensor(tokens[\"input_ids\"]).view(1, -1).to(\"cuda\"),\n                     attention_mask=torch.tensor(tokens[\"attention_mask\"]).view(1, -1).to(\"cuda\"))[\"logits\"].item()\n    output = max(0, output)\n    if output != 0:\n        output = 1\n        \n    targets.append(output)\n    labels.append(train_dataset[i][\"label\"])\n\nfrom sklearn.metrics import accuracy_score\naccuracy_score(labels, targets)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:01:42.460840Z","iopub.execute_input":"2024-08-05T12:01:42.461153Z","iopub.status.idle":"2024-08-05T12:05:04.574019Z","shell.execute_reply.started":"2024-08-05T12:01:42.461122Z","shell.execute_reply":"2024-08-05T12:05:04.573183Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"100%|██████████| 10000/10000 [00:00<00:00, 346513.55it/s]\n100%|██████████| 25000/25000 [03:20<00:00, 124.44it/s]\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0.80912"},"metadata":{}}]}]}